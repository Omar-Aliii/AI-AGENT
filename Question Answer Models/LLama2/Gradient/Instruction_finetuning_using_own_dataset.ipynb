{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Omar-Aliii/AI-AGENT/blob/main/Question%20Answer%20Models/LLama2/Gradient/Instruction_finetuning_using_own_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradientai --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6p4tdiSJm4y",
        "outputId": "59967673-36fa-4ea6-dcbe-33238bb2ed3e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradientai\n",
            "  Downloading gradientai-1.7.0-py3-none-any.whl (270 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.4/270.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aenum>=3.1.11 (from gradientai)\n",
            "  Downloading aenum-3.1.15-py3-none-any.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic<2.0.0,>=1.10.5 (from gradientai)\n",
            "  Downloading pydantic-1.10.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m97.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from gradientai) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from gradientai) (2.0.7)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.0.0,>=1.10.5->gradientai) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->gradientai) (1.16.0)\n",
            "Installing collected packages: aenum, pydantic, gradientai\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.6.1\n",
            "    Uninstalling pydantic-2.6.1:\n",
            "      Successfully uninstalled pydantic-2.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aenum-3.1.15 gradientai-1.7.0 pydantic-1.10.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['GRADIENT_ACCESS_TOKEN'] = \"HEubR77OG4ETgOHwYQfd6VIcTLhvy7ai\"\n",
        "os.environ['GRADIENT_WORKSPACE_ID'] = \"0f99a5d5-209f-43de-b5e4-dd07456cf183_workspace\""
      ],
      "metadata": {
        "id": "MyL8aL3Fedvd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from gradientai import Gradient\n",
        "\n",
        "def main():\n",
        "    with Gradient() as gradient:\n",
        "        base_model = gradient.get_base_model(base_model_slug=\"nous-hermes2\")\n",
        "        new_model_adapter = base_model.create_model_adapter(name=\"test model 3\")\n",
        "        print(f\"Created model adapter with id {new_model_adapter.id}\")\n",
        "\n",
        "        sample_query = \"### Instruction: what is the skin color of Luke Skywalker?\\n\\n### Response:\"\n",
        "        print(f\"Asking: {sample_query}\")\n",
        "\n",
        "        # Before fine-tuning\n",
        "        completion = new_model_adapter.complete(query=sample_query, max_generated_token_count=100).generated_output\n",
        "        print(f\"Generated (before fine-tune): {completion}\")\n",
        "\n",
        "        # Load the CSV data\n",
        "        df = pd.read_csv('characters.csv')\n",
        "        train_texts = df['name'].tolist()\n",
        "        train_labels = df['skin_color'].tolist()\n",
        "\n",
        "        samples = [{\"inputs\": text, \"label\": label} for text, label in zip(train_texts, train_labels)]\n",
        "\n",
        "        # Fine-tuning\n",
        "        num_epochs = 1\n",
        "        batch_size = 8  # Adjust based on GPU memory\n",
        "        total_samples = len(samples)\n",
        "        batches = [samples[i:i + batch_size] for i in range(0, total_samples, batch_size)]\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f\"Fine-tuning the model, epoch {epoch + 1}\")\n",
        "            for batch in batches:\n",
        "                new_model_adapter.fine_tune(samples=batch)\n",
        "\n",
        "        # After fine-tuning\n",
        "        completion = new_model_adapter.complete(query=sample_query, max_generated_token_count=100).generated_output\n",
        "        print(f\"Generated (after fine-tune): {completion}\")\n",
        "\n",
        "        new_model_adapter.delete()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OD7AHzYZei13",
        "outputId": "68396414-f690-4d26-af0b-9cc97f8b46a2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created model adapter with id ef74b97e-65f8-454f-95ef-28fc60dc70cd_model_adapter\n",
            "Asking: ### Instruction: what is the skin color of Luke Skywalker?\n",
            "\n",
            "### Response:\n",
            "Generated (before fine-tune):  Luke Skywalker's skin color is not explicitly stated in the Star Wars films, but he is typically portrayed as having a fair or pale complexion. In the original Star Wars trilogy, Luke is played by Mark Hamill, who has a light complexion. In the prequel trilogy, which takes place before the original trilogy, Luke is portrayed as a young boy by Jake Lloyd, who also has a light complexion.\n",
            "Fine-tuning the model, epoch 1\n",
            "Generated (after fine-tune):  Luke Skywalker's skin color is white.\n"
          ]
        }
      ]
    }
  ]
}