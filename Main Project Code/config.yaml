device_type: cuda
model_name: large-v2
quantization_type: bfloat16
supported_quantizations:
  cpu:
  - int8_float32
  - int8
  - float32
  cuda:
  - int8_float32
  - int8_bfloat16
  - bfloat16
  - int8_float16
  - float16
  - int8
  - float32
